{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('train_files/X_train.npy', mmap_mode='r')\n",
    "y_train=np.load('train_files/y_train_k.npy', mmap_mode='r')\n",
    "X_value = np.load('train_files/X_val.npy', mmap_mode = 'r')\n",
    "y_value = np.load('train_files/y_val_k.npy', mmap_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=np.std(X_train,axis=0)\n",
    "std[std==0]=1\n",
    "X_train = X_train - mean / std\n",
    "X_value = X_value - mean / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = Input(shape = (X_train.shape[1],))\n",
    "x = Dense(4096)(ins)\n",
    "x = Activation('relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(2048)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "outs = Dense(y_train.shape[1], activation = 'relu')(x)\n",
    "\n",
    "model = Model(ins, outs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "model.compile(opt, 'categorical_crossentropy', metrics = ['acc'])\n",
    "stopper = EarlyStopping(monitor='value_acc', patience = 4, mode='auto')\n",
    "checker = ModelCheckpoint('train_files/relu_best.h8', monitor='value_acc', mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.5940 - acc: 0.4355 - val_loss: 6.0062 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CORPUSERS/86007937/PycharmProjects/RL/venv/lib/python3.5/site-packages/keras/callbacks.py:526: RuntimeWarning: Early stopping conditioned on metric `value_acc` which is not available. Available metrics are: loss,val_loss,val_acc,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9891 - acc: 0.8710 - val_loss: 5.9828 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1329 - acc: 1.0000 - val_loss: 5.7785 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0677 - acc: 1.0000 - val_loss: 5.7748 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0460 - acc: 0.9839 - val_loss: 5.7830 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 5.8554 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 5.9274 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 5.8556 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 5.7003 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 5.5912 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 5.4960 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 5.4359 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.3943 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 5.3830 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 5.3971 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.4101 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 9.8651e-04 - acc: 1.0000 - val_loss: 5.4261 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.4441 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.3101e-04 - acc: 1.0000 - val_loss: 5.4662 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.2747e-04 - acc: 1.0000 - val_loss: 5.4832 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.5505e-04 - acc: 1.0000 - val_loss: 5.5018 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.0822e-04 - acc: 1.0000 - val_loss: 5.5165 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4676e-04 - acc: 1.0000 - val_loss: 5.5294 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.4802e-04 - acc: 1.0000 - val_loss: 5.5401 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4382e-04 - acc: 1.0000 - val_loss: 5.5429 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4854e-04 - acc: 1.0000 - val_loss: 5.5504 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4586e-04 - acc: 1.0000 - val_loss: 5.5531 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 4.1386e-04 - acc: 1.0000 - val_loss: 5.5539 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.2018e-04 - acc: 1.0000 - val_loss: 5.5551 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 9.3559e-05 - acc: 1.0000 - val_loss: 5.5573 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.3788e-04 - acc: 1.0000 - val_loss: 5.5560 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 8.4879e-05 - acc: 1.0000 - val_loss: 5.5561 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.0031e-04 - acc: 1.0000 - val_loss: 5.5563 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 7.4297e-05 - acc: 1.0000 - val_loss: 5.5595 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 6.0854e-05 - acc: 1.0000 - val_loss: 5.5636 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 7.2122e-05 - acc: 1.0000 - val_loss: 5.5670 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 6.0550e-05 - acc: 1.0000 - val_loss: 5.5678 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.5160e-05 - acc: 1.0000 - val_loss: 5.5686 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.5554e-05 - acc: 1.0000 - val_loss: 5.5659 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.3969e-05 - acc: 1.0000 - val_loss: 5.5647 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.3087e-05 - acc: 1.0000 - val_loss: 5.5631 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.2563e-05 - acc: 1.0000 - val_loss: 5.5610 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 8.1183e-05 - acc: 1.0000 - val_loss: 5.5585 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.7604e-05 - acc: 1.0000 - val_loss: 5.5579 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 4.8068e-05 - acc: 1.0000 - val_loss: 5.5558 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.8269e-05 - acc: 1.0000 - val_loss: 5.5557 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 4.9595e-05 - acc: 1.0000 - val_loss: 5.5559 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 4.0323e-05 - acc: 1.0000 - val_loss: 5.5562 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.7480e-05 - acc: 1.0000 - val_loss: 5.5572 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.7001e-05 - acc: 1.0000 - val_loss: 5.5582 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.5769e-05 - acc: 1.0000 - val_loss: 5.5597 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.8621e-05 - acc: 1.0000 - val_loss: 5.5599 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.3897e-05 - acc: 1.0000 - val_loss: 5.5578 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.1820e-05 - acc: 1.0000 - val_loss: 5.5601 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.0146e-05 - acc: 1.0000 - val_loss: 5.5626 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 9.9626e-05 - acc: 1.0000 - val_loss: 5.5615 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.5758e-05 - acc: 1.0000 - val_loss: 5.5615 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.7852e-05 - acc: 1.0000 - val_loss: 5.5627 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.4608e-05 - acc: 1.0000 - val_loss: 5.5643 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.5652e-05 - acc: 1.0000 - val_loss: 5.5656 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 7ms/step - loss: 2.9646e-05 - acc: 1.0000 - val_loss: 5.5683 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.6409e-05 - acc: 1.0000 - val_loss: 5.5710 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 3.0417e-05 - acc: 1.0000 - val_loss: 5.5742 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.8094e-05 - acc: 1.0000 - val_loss: 5.5760 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.9001e-05 - acc: 1.0000 - val_loss: 5.5802 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.4475e-05 - acc: 1.0000 - val_loss: 5.5851 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 3.2869e-05 - acc: 1.0000 - val_loss: 5.5888 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2206e-05 - acc: 1.0000 - val_loss: 5.5922 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.6452e-05 - acc: 1.0000 - val_loss: 5.5972 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.2089e-05 - acc: 1.0000 - val_loss: 5.5999 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.5081e-05 - acc: 1.0000 - val_loss: 5.6028 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.0348e-05 - acc: 1.0000 - val_loss: 5.6051 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.1473e-04 - acc: 1.0000 - val_loss: 5.6010 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.2373e-05 - acc: 1.0000 - val_loss: 5.5999 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.8188e-05 - acc: 1.0000 - val_loss: 5.6002 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.8505e-05 - acc: 1.0000 - val_loss: 5.6019 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.8875e-05 - acc: 1.0000 - val_loss: 5.6035 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 2.0920e-05 - acc: 1.0000 - val_loss: 5.6064 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.9011e-05 - acc: 1.0000 - val_loss: 5.6097 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.8543e-05 - acc: 1.0000 - val_loss: 5.6139 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 4.1988e-05 - acc: 1.0000 - val_loss: 5.6162 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6806e-05 - acc: 1.0000 - val_loss: 5.6206 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0464e-04 - acc: 1.0000 - val_loss: 5.6211 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.9274e-05 - acc: 1.0000 - val_loss: 5.6236 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.6966e-05 - acc: 1.0000 - val_loss: 5.6264 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.6442e-05 - acc: 1.0000 - val_loss: 5.6306 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.7217e-05 - acc: 1.0000 - val_loss: 5.6349 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.6452e-05 - acc: 1.0000 - val_loss: 5.6396 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.6331e-05 - acc: 1.0000 - val_loss: 5.6453 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.6013e-05 - acc: 1.0000 - val_loss: 5.6504 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.9369e-05 - acc: 1.0000 - val_loss: 5.6553 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.5927e-05 - acc: 1.0000 - val_loss: 5.6595 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.4049e-05 - acc: 1.0000 - val_loss: 5.6638 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.0215e-05 - acc: 1.0000 - val_loss: 5.6668 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.3951e-05 - acc: 1.0000 - val_loss: 5.6710 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.4914e-05 - acc: 1.0000 - val_loss: 5.6755 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.6106e-05 - acc: 1.0000 - val_loss: 5.6764 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.6390e-05 - acc: 1.0000 - val_loss: 5.6804 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3986e-05 - acc: 1.0000 - val_loss: 5.6843 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.5003e-05 - acc: 1.0000 - val_loss: 5.6873 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6c51044828>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100, batch_size=32,\n",
    "          validation_data=(X_value, y_value),\n",
    "          callbacks = [stopper, checker])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('train_files/relu_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 85)                87125     \n",
      "=================================================================\n",
      "Total params: 11,657,301\n",
      "Trainable params: 11,642,965\n",
      "Non-trainable params: 14,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5514478e-03, 2.1826949e-03, 1.1054078e-02, ..., 1.0501348e-03,\n",
       "        8.2763704e-03, 7.7868142e-04],\n",
       "       [2.4214631e-03, 3.8514249e-03, 9.6804267e-03, ..., 1.4592613e-03,\n",
       "        5.4627634e-03, 8.0791482e-04],\n",
       "       [3.3372545e-01, 1.1900924e-03, 2.4899904e-01, ..., 8.4386074e-06,\n",
       "        3.9093927e-03, 2.6383254e-04],\n",
       "       ...,\n",
       "       [4.3670021e-02, 5.8798149e-04, 3.1326973e-01, ..., 1.9681395e-03,\n",
       "        1.6593380e-02, 4.3861051e-03],\n",
       "       [4.3279370e-03, 2.1257850e-03, 1.3717511e-02, ..., 1.0286479e-03,\n",
       "        1.6914537e-02, 7.9546748e-03],\n",
       "       [5.1227486e-04, 6.1548217e-03, 3.1907037e-03, ..., 1.6723889e-03,\n",
       "        2.5697667e-02, 1.3130454e-04]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value_predicts= model.predict(X_value)\n",
    "Value_predicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "intPredictValue=np.array([np.argmax(r) for r in Value_predicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70, 70,  0,  3,  0,  0,  2, 39, 39, 39,  3, 70, 70])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intPredictValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_Y_value=np.array([np.argmax(r) for r in y_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58, 59, 16, 36, 11, 13, 19, 50, 57, 51, 23, 47, 68])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int_Y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc=accuracy_score(Int_Y_value,intPredictValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
